# ml_model.py
import pandas as pd
import logging
import pickle
from datetime import datetime
from sqlalchemy import create_engine, Column, Integer, LargeBinary, DateTime
from sqlalchemy.orm import sessionmaker, declarative_base
from sklearn.ensemble import RandomForestClassifier

# ... (preprocess_and_add_featuresé–¢æ•°ãªã©ã¯å‰å›ã¨åŒæ§˜)

# --- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«å®šç¾© ---
Base = declarative_base()
class AIModel(Base):
    __tablename__ = 'ai_models'
    id = Column(Integer, primary_key=True)
    model_data = Column(LargeBinary, nullable=False)
    accuracy = Column(Float, nullable=True) # ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦ã‚’è¨˜éŒ²
    created_at = Column(DateTime, default=datetime.utcnow)

# --- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œ ---
def save_model_to_db(model, engine, accuracy_score):
    Session = sessionmaker(bind=engine)
    session = Session()
    try:
        serialized_model = pickle.dumps(model)
        new_model = AIModel(model_data=serialized_model, accuracy=accuracy_score)
        session.add(new_model)
        session.commit()
        logging.info(f"New AI model with accuracy {accuracy_score:.2f} saved to database.")
    except Exception as e:
        session.rollback(); logging.error(f"Failed to save model to DB: {e}")
    finally:
        session.close()

def load_latest_model_from_db(engine):
    Session = sessionmaker(bind=engine)
    session = Session()
    try:
        latest_model_record = session.query(AIModel).order_by(AIModel.created_at.desc()).first()
        if latest_model_record:
            logging.info(f"Loading latest AI model (trained at {latest_model_record.created_at}) from database.")
            return pickle.loads(latest_model_record.model_data)
        return None
    except Exception as e:
        logging.error(f"Failed to load model from DB: {e}"); return None
    finally:
        session.close()

# --- ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã¨åˆ†æ ---
def train_and_evaluate_model(all_data):
    """ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã€è©•ä¾¡ã™ã‚‹"""
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import accuracy_score

    # preprocess_and_add_featuresã¯å‰å›æç¤ºã—ãŸã‚³ãƒ¼ãƒ‰ã«ã‚ã‚‹ã¨ä»®å®š
    X, y, _ = preprocess_and_add_features(all_data)
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’è¨“ç·´ç”¨ã¨ãƒ†ã‚¹ãƒˆç”¨ã«åˆ†å‰²ã—ã¦ç²¾åº¦ã‚’è©•ä¾¡
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    
    model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)
    model.fit(X_train, y_train)
    
    predictions = model.predict(X_test)
    accuracy = accuracy_score(y_test, predictions)
    
    # æœ€çµ‚çš„ãªãƒ¢ãƒ‡ãƒ«ã¯å…¨ãƒ‡ãƒ¼ã‚¿ã§å†è¨“ç·´ã™ã‚‹
    final_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)
    final_model.fit(X, y) # å…¨ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’
    
    return final_model, accuracy

def run_daily_retraining(engine, data_aggregator):
    """
    1æ—¥1å›å®Ÿè¡Œã•ã‚Œã‚‹ãƒ¡ã‚¤ãƒ³ã®å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã€‚
    æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€ãƒ¢ãƒ‡ãƒ«ã‚’å†è¨“ç·´ã—ã¦DBã«ä¿å­˜ã™ã‚‹ã€‚
    """
    logging.info("ğŸ¤– Starting daily AI model retraining process...")
    all_data = data_aggregator.get_all_chains_data()
    if all_data.empty:
        logging.error("No data available for retraining. Aborting.")
        return

    # ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã€ç²¾åº¦ã‚’è©•ä¾¡
    new_model, accuracy = train_and_evaluate_model(all_data)
    
    # æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’DBã«ä¿å­˜
    save_model_to_db(new_model, engine, accuracy)
    logging.info("âœ… Daily AI model retraining process finished.")
