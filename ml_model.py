# ml_model.py
import pandas as pd
import logging
import pickle
from datetime import datetime
from sqlalchemy import create_engine, Column, Integer, LargeBinary, DateTime, Float # <--- Floatã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from sqlalchemy.orm import sessionmaker
from sqlalchemy.orm import declarative_base
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import pandas_ta as ta

# --- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾© ---
Base = declarative_base()

class AIModel(Base):
    """
    è¨“ç·´æ¸ˆã¿AIãƒ¢ãƒ‡ãƒ«ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã™ã‚‹ãŸã‚ã®ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©ã€‚
    """
    __tablename__ = 'ai_models'
    id = Column(Integer, primary_key=True)
    model_data = Column(LargeBinary, nullable=False)
    accuracy = Column(Float, nullable=True) # ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦ã‚’è¨˜éŒ²
    created_at = Column(DateTime, default=datetime.utcnow)

# --- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œ ---
def save_model_to_db(model, engine, accuracy_score):
    """è¨“ç·´æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®šã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã™ã‚‹ã€‚"""
    Session = sessionmaker(bind=engine)
    session = Session()
    try:
        serialized_model = pickle.dumps(model)
        new_model = AIModel(model_data=serialized_model, accuracy=accuracy_score)
        session.add(new_model)
        session.commit()
        logging.info(f"New AI model with accuracy {accuracy_score:.2f} has been saved to the database.")
    except Exception as e:
        session.rollback()
        logging.error(f"Failed to save model to DB: {e}")
    finally:
        session.close()

def load_latest_model_from_db(engine):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰æœ€æ–°ã®è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã€‚"""
    Session = sessionmaker(bind=engine)
    session = Session()
    try:
        latest_model_record = session.query(AIModel).order_by(AIModel.created_at.desc()).first()
        if latest_model_record:
            logging.info(f"Loading latest AI model (trained at {latest_model_record.created_at}, accuracy: {latest_model_record.accuracy:.2f}) from database.")
            return pickle.loads(latest_model_record.model_data)
        logging.warning("No model found in the database.")
        return None
    except Exception as e:
        logging.error(f"Failed to load model from DB: {e}")
        return None
    finally:
        session.close()

# --- ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã¨ãƒ¢ãƒ‡ãƒ«è¨“ç·´ ---
def preprocess_and_add_features(df):
    """ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã¨ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ï¼ˆç‰¹å¾´é‡ï¼‰ã‚’è¿½åŠ ã™ã‚‹ã€‚"""
    try:
        # ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ã‚’è¿½åŠ 
        df.ta.rsi(append=True)
        df.ta.macd(append=True)
        df.ta.bbands(append=True)

        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼ˆç›®çš„å¤‰æ•°ï¼‰ã‚’ä½œæˆ
        df['Price_Dir'] = (df['Close'].pct_change() > 0).astype(int)
        df = df.dropna()
        
        # ãƒ¢ãƒ‡ãƒ«ãŒä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡ã‚’å®šç¾©
        features = [
            'Open', 'High', 'Low', 'Close', 'Volume', 
            'RSI_14', 'MACDh_12_26_9', 'BBL_20_2.0', 'BBM_20_2.0', 'BBU_20_2.0'
        ]
        
        # ç‰¹å¾´é‡ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
        available_features = [f for f in features if f in df.columns]
        if len(available_features) < len(features):
            logging.warning(f"Some features are missing. Available: {available_features}")

        X = df[available_features]
        y = df['Price_Dir']
        
        return X, y, df
    except Exception as e:
        logging.error(f"Error during preprocessing: {e}")
        return pd.DataFrame(), pd.Series(), pd.DataFrame()


def train_and_evaluate_model(all_data):
    """ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã€ç²¾åº¦ã‚’è©•ä¾¡ã—ã¦æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã‚’è¿”ã™ã€‚"""
    X, y, _ = preprocess_and_add_features(all_data)
    if X.empty:
        return None, 0

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    
    model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)
    model.fit(X_train, y_train)
    
    predictions = model.predict(X_test)
    accuracy = accuracy_score(y_test, predictions)
    
    # æœ€çµ‚çš„ãªãƒ¢ãƒ‡ãƒ«ã¯å…¨ãƒ‡ãƒ¼ã‚¿ã§å†è¨“ç·´ã™ã‚‹
    final_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)
    final_model.fit(X, y)
    
    return final_model, accuracy

def run_daily_retraining(engine, data_aggregator):
    """
    1æ—¥1å›å®Ÿè¡Œã•ã‚Œã‚‹ãƒ¡ã‚¤ãƒ³ã®å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã€‚
    æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€ãƒ¢ãƒ‡ãƒ«ã‚’å†è¨“ç·´ã—ã¦DBã«ä¿å­˜ã™ã‚‹ã€‚
    """
    logging.info("ğŸ¤– Starting daily AI model retraining process...")
    # data_aggregatorã¯yfinanceãªã©ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹å‰æ
    all_data = data_aggregator.get_historical_data_for_training()
    if all_data.empty:
        logging.error("No data available for retraining. Aborting.")
        return

    new_model, accuracy = train_and_evaluate_model(all_data)
    
    if new_model:
        save_model_to_db(new_model, engine, accuracy)
    
    logging.info("âœ… Daily AI model retraining process finished.")
