# ==============================================================================
#
# ğŸš€ è¶…é«˜æ€§èƒ½ç‰ˆ Colab ãƒœãƒƒãƒˆï¼ˆCoinbaseå°‚ç”¨ï¼‰ - æœ€çµ‚å®Œå…¨ç‰ˆ
#
# âœ… ã™ã¹ã¦ã®ã‚¨ãƒ©ãƒ¼ã¨è­¦å‘Šã‚’ä¿®æ­£ã—ã€å®‰å®šç¨¼åƒã‚’ç¢ºä¿
# âœ… Google Driveã‹ã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã®è‡ªå‹•èª­ã¿è¾¼ã¿ãƒ»ä¿å­˜æ©Ÿèƒ½ã‚’å®Ÿè£…
# âœ… ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ°¸ç¶šåŒ–ã—ã€èµ·å‹•æ™‚ã‹ã‚‰æ©Ÿèƒ½ã™ã‚‹ã‚ˆã†æ”¹å–„
# âœ… ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ­ã‚¸ãƒƒã‚¯ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã€æ€§èƒ½ã‚’åŠ‡çš„ã«å‘ä¸Š
#
# ==============================================================================

# ===== ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ— =====
# âš ï¸ ã“ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œå¾Œã€å¿…ãš**ã€Œãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚’å†èµ·å‹•ã€**ã—ã¦ã‹ã‚‰å†åº¦å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚
# ã“ã‚Œã«ã‚ˆã‚Šã€ä¾å­˜é–¢ä¿‚ã®ç«¶åˆãŒå®Œå…¨ã«è§£æ¶ˆã•ã‚Œã¾ã™ã€‚
!pip uninstall -y numpy pandas scikit-learn lightgbm xgboost ta ccxt matplotlib joblib pandas-ta
!pip install --force-reinstall numpy==1.26.4 pandas==2.2.2 scikit-learn lightgbm xgboost matplotlib joblib ccxt
!pip install ta pandas-ta

# ===== Google Driveã®ãƒã‚¦ãƒ³ãƒˆ =====
# æ±‚ã‚ã‚‰ã‚ŒãŸã‚‰ã€ŒGoogle Driveã«æ¥ç¶šã€ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦è¨±å¯ã—ã¦ãã ã•ã„ã€‚
from google.colab import drive
drive.mount('/content/drive')

import os, sys, time, math, io, gc, traceback, warnings, random
warnings.filterwarnings("ignore")

import ccxt
import numpy as np
import pandas as pd
import requests
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from datetime import datetime, timezone
from typing import Tuple, Dict, List

# ---- ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿ ----
import joblib

# ---- ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ ----
from ta.momentum import RSIIndicator, StochRSIIndicator
from ta.trend import EMAIndicator, MACD, ADXIndicator
from ta.volatility import AverageTrueRange, BollingerBands, KeltnerChannel
from ta.volume import OnBalanceVolumeIndicator
import pandas_ta as pta

# ---- æ©Ÿæ¢°å­¦ç¿’ ----
import lightgbm as lgb
import xgboost as xgb
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import f1_score
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import StackingClassifier
from sklearn.linear_model import LogisticRegression

# ================== è¨­å®š ==================
# âš ï¸ æ³¨æ„: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯ã‚’æ‰¿çŸ¥ã®ä¸Šã§å¹³æ–‡ã§APIã‚­ãƒ¼ã‚’è¨˜è¿°ã—ã¾ã™ã€‚
# ã“ã®ã‚³ãƒ¼ãƒ‰ã‚’å…¬é–‹ã—ãªã„ã§ãã ã•ã„ã€‚
TELEGRAM_TOKEN = '7904380124:AAE2AuRITmgBw5OECTELF5151D3pRz4K9JM'
TELEGRAM_CHAT_ID = '5890119671'

MODEL_DIR = '/content/drive/MyDrive/crypto_models'

WATCHLIST = [
  "BTC/USD", "ETH/USD", "XRP/USD", "SOL/USD", "HBAR/USD", "SUI/USD", "DOGE/USD",
  "BONK/USD", "PENGU/USD", "XLM/USD", "ADA/USD", "LINK/USD", "IDEX/USD",
  "LTC/USD", "ENA/USD", "BCH/USD", "WIF/USD", "AVAX/USD", "SEI/USD", "DOT/USD"
]

QUALITY_NOTIFY_THRESHOLD = 65
MIN_BARS = 250
MAIN_LOOP_SLEEP_SEC = 60 * 30
EXCHANGE_ID = 'coinbase'
exchange = ccxt.coinbase({'enableRateLimit': True})

PING_INTERVAL_SEC = 60 * 5
ALIVE_NOTIFY_INTERVAL_SEC = 60 * 60 * 6

# ================== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ==================
def retry(max_tries=5, delay=1.0, backoff=2.0, exceptions=(Exception,)):
    def deco(fn):
        def wrapper(*args, **kwargs):
            d = delay
            for i in range(1, max_tries + 1):
                try:
                    return fn(*args, **kwargs)
                except exceptions as e:
                    print(f"âš ï¸ ãƒªãƒˆãƒ©ã‚¤å®Ÿè¡Œä¸­... ({i}/{max_tries}) ã‚¨ãƒ©ãƒ¼: {e}")
                    if i == max_tries:
                        raise
                    time.sleep(d)
                    d *= backoff
        return wrapper
    return deco

class TelegramNotifier:
    def __init__(self, token, chat_id):
        self.token = token
        self.chat_id = chat_id
        self.base_url = f'https://api.telegram.org/bot{self.token}'
        self.is_enabled = bool(self.token and self.chat_id)

    @retry(max_tries=3, delay=2.0, exceptions=(requests.exceptions.RequestException,))
    def send_message(self, text):
        if not self.is_enabled:
            print("âŒ Telegramãƒˆãƒ¼ã‚¯ãƒ³ã¾ãŸã¯ãƒãƒ£ãƒƒãƒˆIDãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚é€šçŸ¥ã¯ç„¡åŠ¹ã§ã™ã€‚")
            return
        try:
            url = f"{self.base_url}/sendMessage"
            payload = {
                'chat_id': self.chat_id,
                'text': text,
                'parse_mode': 'HTML'
            }
            response = requests.post(url, data=payload, timeout=10)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            print(f"âŒ Telegramãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            raise

    @retry(max_tries=3, delay=2.0, exceptions=(requests.exceptions.RequestException,))
    def send_photo(self, photo_data, caption):
        if not self.is_enabled:
            print("âŒ Telegramãƒˆãƒ¼ã‚¯ãƒ³ã¾ãŸã¯ãƒãƒ£ãƒƒãƒˆIDãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚é€šçŸ¥ã¯ç„¡åŠ¹ã§ã™ã€‚")
            return
        try:
            url = f"{self.base_url}/sendPhoto"
            files = {'photo': ('chart.png', photo_data, 'image/png')}
            payload = {
                'chat_id': self.chat_id,
                'caption': caption,
                'parse_mode': 'HTML'
            }
            response = requests.post(url, data=payload, files=files, timeout=20)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            print(f"âŒ Telegramå†™çœŸé€ä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            raise

def now_utc_str():
    return datetime.now(timezone.utc).strftime("%Y-%m-%d %H:%M:%S UTC")

def fmt_price(x, digits=6):
    if x is None or (isinstance(x, float) and (math.isnan(x) or math.isinf(x))):
        return "-"
    s = f"{x:.{digits}f}"
    s = s.rstrip('0').rstrip('.') if '.' in s else s
    return s

def escape_html(text):
    return text.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;").replace('"', "&quot;").replace("'", '&#39;')

def symbol_icon(symbol):
    icon_map = {
        "BTC": "â‚¿", "ETH": "Î", "XRP": "ğŸª", "SOL": "â˜€ï¸", "DOGE": "ğŸ¶",
        "BONK": "ğŸ•", "PENGU": "ğŸ§", "HBAR": "H", "SUI": "ğŸŒŠ",
        "XLM": "â­", "ADA": "â‚³", "LINK": "ğŸ”—", "IDEX": "âš¡",
        "LTC": "Å", "ENA": "ğŸ’µ", "BCH": "ğŸŒ±", "WIF": "ğŸ‘’",
        "AVAX": "ğŸ”º", "SEI": "ğŸŒŠ", "DOT": "âš«"
    }
    prefix = symbol.split('/')[0]
    return icon_map.get(prefix, 'ğŸ’')

def detect_candles(df_tail):
    if len(df_tail) < 3: return {"bull_engulf": False, "bear_engulf": False, "bull_pin": False, "bear_pin": False}

    bull_engulf = (df_tail.iloc[-1]['close'] > df_tail.iloc[-2]['open'] and
                   df_tail.iloc[-1]['open'] < df_tail.iloc[-2]['close'] and
                   (df_tail.iloc[-2]['close'] - df_tail.iloc[-2]['open'] < 0))
    bear_engulf = (df_tail.iloc[-1]['close'] < df_tail.iloc[-2]['open'] and
                   df_tail.iloc[-1]['open'] > df_tail.iloc[-2]['close'] and
                   (df_tail.iloc[-2]['close'] - df_tail.iloc[-2]['open'] > 0))
    bull_pin = (df_tail.iloc[-1]['open'] < df_tail.iloc[-1]['close'] and
                (df_tail.iloc[-1]['close'] - df_tail.iloc[-1]['open']) / (df_tail.iloc[-1]['high'] - df_tail.iloc[-1]['low']) > 0.6)
    bear_pin = (df_tail.iloc[-1]['open'] > df_tail.iloc[-1]['close'] and
                (df_tail.iloc[-1]['open'] - df_tail.iloc[-1]['close']) / (df_tail.iloc[-1]['high'] - df_tail.iloc[-1]['low']) > 0.6)

    return {"bull_engulf": bull_engulf, "bear_engulf": bear_engulf, "bull_pin": bull_pin, "bear_pin": bear_pin}


# ================== ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¯ãƒ©ã‚¹ ==================
class DataProcessor:
    def __init__(self, exchange_client):
        self.exchange = exchange_client

    def get_ohlcv(self, symbol: str, timeframe='1h', limit=5000) -> pd.DataFrame:
        all_ohlcv = []
        now = self.exchange.milliseconds()

        # éå»5000æœ¬ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å–å¾—é–‹å§‹
        since = now - (5000 * 60 * 60 * 1000)

        while True:
            try:
                data = self.exchange.fetch_ohlcv(symbol, timeframe, since=since, limit=1000)
                if not data:
                    break

                all_ohlcv.extend(data)

                since = data[-1][0] + 1

                time.sleep(self.exchange.rateLimit / 1000)

            except Exception as e:
                print(f"âŒ {symbol} ã®OHLCVãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                return None

        if not all_ohlcv:
            print(f"âŒ {symbol}: éå»ã®OHLCVãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            return None

        df = pd.DataFrame(all_ohlcv, columns=["time", "open", "high", "low", "close", "volume"])
        df.drop_duplicates(subset=['time'], inplace=True)
        df["time"] = pd.to_datetime(df["time"], unit='ms', utc=True)
        df.set_index("time", inplace=True)
        df = df.astype(float)

        return df.sort_index()

    def add_features(self, df: pd.DataFrame) -> pd.DataFrame:
        if df is None or df.empty: return pd.DataFrame()

        out = df.copy()
        try:
            out['ema_12'] = EMAIndicator(out['close'], window=12).ema_indicator()
            out['ema_26'] = EMAIndicator(out['close'], window=26).ema_indicator()
            out['ema_50'] = EMAIndicator(out['close'], window=50).ema_indicator()
            out['rsi'] = RSIIndicator(out['close'], window=14).rsi()
            out['stoch_rsi'] = StochRSIIndicator(out['close'], window=14, smooth1=3, smooth2=3).stochrsi()
            macd = MACD(out['close'], window_slow=26, window_fast=12, window_sign=9)
            out['macd'] = macd.macd()
            out['macd_diff'] = macd.macd_diff()
            out['adx'] = ADXIndicator(out['high'], out['low'], out['close'], window=14).adx()
            out['atr'] = AverageTrueRange(out['high'], out['low'], out['close'], window=14).average_true_range()
            out['obv'] = OnBalanceVolumeIndicator(out['close'], out['volume']).on_balance_volume()

            for window in [1, 2, 3, 5]:
                out[f'close_lag_{window}'] = out['close'].shift(window)
                out[f'volume_lag_{window}'] = out['volume'].shift(window)
                out[f'rsi_lag_{window}'] = out['rsi'].shift(window)

            bb = BollingerBands(out['close'], window=20, window_dev=2)
            out['bb_hi'] = bb.bollinger_hband()
            out['bb_lo'] = bb.bollinger_lband()
            out['bb_width'] = bb.bollinger_wband()

            kc = KeltnerChannel(out['high'], out['low'], out['close'], window=20, window_atr=10, multiplier=2)
            out['kc_hi'] = kc.keltner_channel_hband()
            out['kc_lo'] = kc.keltner_channel_lband()

            df_temp = pd.DataFrame(index=out.index)
            df_temp['high'] = out['high']
            df_temp['low'] = out['low']
            df_temp['close'] = out['close']
            super_trend_series = pta.supertrend(df_temp['high'], df_temp['low'], df_temp['close'], length=10, multiplier=3)
            out['super_trend'] = super_trend_series.iloc[:, 0]

            out['ema_ratio'] = (out['ema_12'] - out['ema_26']) / out['ema_26']
            out['price_to_ema50'] = (out['close'] - out['ema_50']) / out['ema_50']
            out['vol_change'] = out['volume'].pct_change()
            out['macd_hist_change'] = out['macd_diff'].pct_change()

            out['rsi_norm'] = out['rsi'] / 100
            out['macd_norm'] = out['macd'] / out['close'] * 1000

            out.dropna(inplace=True)
            return out

        except Exception as e:
            print(f"âŒ ç‰¹å¾´é‡è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return pd.DataFrame()

# ================== ãƒˆãƒ¬ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒãƒˆã‚¯ãƒ©ã‚¹ ==================
class TradingBot:
    def __init__(self, data_processor, notifier, watchlist):
        self.data_processor = data_processor
        self.notifier = notifier
        self.watchlist = watchlist
        self.models = {}
        self.backtest_data = {}

        os.makedirs(MODEL_DIR, exist_ok=True)

        self.check_models_and_load_or_train()

    def check_models_and_load_or_train(self):
        training_needed = False
        for symbol in self.watchlist:
            sanitized_symbol = symbol.replace('/', '')
            stack_path = os.path.join(MODEL_DIR, f'stack_model_{sanitized_symbol}.pkl')
            backtest_path = os.path.join(MODEL_DIR, f'backtest_data_{sanitized_symbol}.pkl')

            if not os.path.exists(stack_path) or not os.path.exists(backtest_path):
                training_needed = True
                break

        if training_needed:
            print("ğŸ’¡ 1ã¤ä»¥ä¸Šã®ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ–°è¦ã«å…¨ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã‚’é–‹å§‹ã—ã¾ã™...")
            self.train_all_models()
        else:
            print("âœ… ã™ã¹ã¦ã®è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¨ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒGoogle Driveã«å­˜åœ¨ã—ã¾ã™ã€‚èª­ã¿è¾¼ã¿ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
            self.load_all_models()

    def load_all_models(self):
        for symbol in self.watchlist:
            self.load_models(symbol)

    def train_all_models(self):
        for symbol in self.watchlist:
            try:
                print(f"â³ {symbol} ã®ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã‚’é–‹å§‹ã—ã¾ã™...")
                df_train = self.data_processor.get_ohlcv(symbol, timeframe='1h', limit=5000)
                if df_train is None or df_train.empty:
                    print(f"âŒ {symbol}: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã€è¨“ç·´ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                    continue

                df_train_features = self.data_processor.add_features(df_train)
                if df_train_features.empty or len(df_train_features) < MIN_BARS:
                    print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãŒãƒ¢ãƒ‡ãƒ«è¨“ç·´ã«ä¸ååˆ†ã§ã™ã€‚æœ€çµ‚çš„ãªãƒ‡ãƒ¼ã‚¿æ•°: {len(df_train_features)} / å¿…è¦ãªãƒ‡ãƒ¼ã‚¿æ•°: {MIN_BARS}")
                    continue

                stack_model, backtest_df = self.train_stacking_model(df_train_features)
                if stack_model is not None and not backtest_df.empty:
                    self.save_models_and_data(symbol, stack_model, backtest_df)
                    self.backtest_data[symbol] = backtest_df
                else:
                    print(f"âŒ {symbol}: ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã¾ãŸã¯ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

            except Exception as e:
                print(f"âŒ {symbol} ã®ãƒ¢ãƒ‡ãƒ«è¨“ç·´ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                traceback.print_exc()

        print("âœ… å…¨ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã¨ä¿å­˜ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

    def train_stacking_model(self, df: pd.DataFrame) -> Tuple[StackingClassifier, pd.DataFrame]:
        df['future_return'] = df['close'].pct_change().shift(-1)
        df['direction'] = (df['future_return'] > 0).astype(int)

        features = [
            'ema_12', 'ema_26', 'ema_50', 'rsi', 'stoch_rsi', 'macd', 'macd_diff', 'adx', 'atr', 'obv',
            'close_lag_1', 'volume_lag_1', 'rsi_lag_1', 'close_lag_2', 'volume_lag_2', 'rsi_lag_2',
            'close_lag_3', 'volume_lag_3', 'rsi_lag_3', 'close_lag_5', 'volume_lag_5', 'rsi_lag_5',
            'bb_hi', 'bb_lo', 'bb_width', 'ema_ratio', 'price_to_ema50', 'vol_change',
            'macd_hist_change', 'rsi_norm', 'macd_norm', 'kc_hi', 'kc_lo', 'super_trend'
        ]

        required_cols = features + ['direction', 'open', 'close', 'low', 'high', 'volume', 'atr']
        df_clean = df.drop(columns=[col for col in df.columns if col not in required_cols])
        df_clean = df_clean.dropna()

        if len(df_clean) < MIN_BARS:
            return None, pd.DataFrame()

        X = df_clean[features]
        y = df_clean['direction']

        tscv = TimeSeriesSplit(n_splits=10)
        stack_scores = []
        stack_models = []
        backtest_df = pd.DataFrame()

        estimators = [
            ('lgbm', lgb.LGBMClassifier(objective='binary', n_estimators=100, learning_rate=0.05, num_leaves=15, max_depth=4, random_state=42, class_weight='balanced')),
            ('xgb', xgb.XGBClassifier(objective='binary:logistic', n_estimators=100, learning_rate=0.05, max_depth=4, use_label_encoder=False, eval_metric='logloss', random_state=42, scale_pos_weight=sum(y==0)/sum(y==1)))
        ]
        stack_model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())

        for train_index, test_index in tscv.split(X):
            X_train, X_test = X.iloc[train_index], X.iloc[test_index]
            y_train, y_test = y.iloc[train_index], y.iloc[test_index]

            stack_model.fit(X_train, y_train)
            stack_scores.append(f1_score(y_test, stack_model.predict(X_test)))
            stack_models.append(stack_model)

            test_data = df_clean.iloc[test_index].copy()
            test_data['stack_pred'] = stack_model.predict(X_test)
            test_data['stack_prob'] = stack_model.predict_proba(X_test)[:, 1]
            backtest_df = pd.concat([backtest_df, test_data])

        best_stack = stack_models[np.argmax(stack_scores)]
        best_stack.fit(X, y)
        return best_stack, backtest_df

    def save_models_and_data(self, symbol, stack_model, backtest_df):
        sanitized_symbol = symbol.replace('/', '')
        try:
            joblib.dump(stack_model, os.path.join(MODEL_DIR, f'stack_model_{sanitized_symbol}.pkl'))
            joblib.dump(backtest_df, os.path.join(MODEL_DIR, f'backtest_data_{sanitized_symbol}.pkl'))
            print(f"âœ… {symbol} ã®ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã¨ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ­£å¸¸ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
        except Exception as e:
            print(f"âŒ {symbol} ã®ãƒ¢ãƒ‡ãƒ«ã¾ãŸã¯ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    def load_models(self, symbol):
        sanitized_symbol = symbol.replace('/', '')
        stack_path = os.path.join(MODEL_DIR, f'stack_model_{sanitized_symbol}.pkl')
        backtest_path = os.path.join(MODEL_DIR, f'backtest_data_{sanitized_symbol}.pkl')

        try:
            stack_model = joblib.load(stack_path)
            backtest_df = joblib.load(backtest_path)
            self.models[symbol] = {'stack': stack_model}
            self.backtest_data[symbol] = backtest_df
            print(f"âœ… {symbol} ã®ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã¨ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ­£å¸¸ã«èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
            return True
        except FileNotFoundError:
            print(f"âš ï¸ {symbol} ã®ãƒ¢ãƒ‡ãƒ«ã¾ãŸã¯ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã“ã®éŠ˜æŸ„ã®åˆ†æã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ã€‚")
            return False
        except Exception as e:
            print(f"âŒ {symbol} ã®ãƒ¢ãƒ‡ãƒ«ã¾ãŸã¯ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return False

    def run_backtest(self, df: pd.DataFrame) -> Dict:
        if df is None or df.empty:
            print(f"â„¹ï¸ ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            return {'total_trades': 0, 'win_rate': 0.0, 'total_pnl': 0.0, 'sharpe_ratio': 0.0, 'max_drawdown': 0.0}

        df = df.copy()

        PRED_PROB_THRESHOLD = 0.6
        df['signal'] = np.where(df['stack_prob'] >= PRED_PROB_THRESHOLD, df['stack_pred'], np.nan)
        df['trade_pnl'] = np.nan

        FEE = 0.001
        SLIPPAGE = 0.0001

        df['entry_price'] = df['open'].shift(-1) * (1 + SLIPPAGE * (2 * df['signal'] - 1))

        df['sl_price'] = df['entry_price'] + df['atr'] * 1.5 * (2 * df['signal'] - 1) * -1
        df['tp_price'] = df['entry_price'] + df['atr'] * 3.0 * (2 * df['signal'] - 1)

        long_closed_sl = (df['low'].shift(-1) <= df['sl_price']) & (df['signal'] == 1)
        long_closed_tp = (df['high'].shift(-1) >= df['tp_price']) & (df['signal'] == 1)
        short_closed_sl = (df['high'].shift(-1) >= df['sl_price']) & (df['signal'] == 0)
        short_closed_tp = (df['low'].shift(-1) <= df['tp_price']) & (df['signal'] == 0)

        df.loc[long_closed_sl, 'trade_pnl'] = (df['sl_price'] - df['entry_price']) / df['entry_price']
        df.loc[long_closed_tp, 'trade_pnl'] = (df['tp_price'] - df['entry_price']) / df['entry_price']
        df.loc[short_closed_sl, 'trade_pnl'] = (df['entry_price'] - df['sl_price']) / df['entry_price']
        df.loc[short_closed_tp, 'trade_pnl'] = (df['entry_price'] - df['tp_price']) / df['entry_price']

        not_closed = (df['signal'].notna()) & (df['trade_pnl'].isna())
        df.loc[not_closed & (df['signal'] == 1), 'trade_pnl'] = (df['close'].shift(-1) - df['entry_price']) / df['entry_price']
        df.loc[not_closed & (df['signal'] == 0), 'trade_pnl'] = (df['entry_price'] - df['close'].shift(-1)) / df['entry_price']

        df['pnl_after_fee'] = df['trade_pnl'] - FEE

        total_trades = df['signal'].notna().sum()
        winning_trades = (df['pnl_after_fee'] > 0).sum()
        total_pnl = df['pnl_after_fee'].sum()
        win_rate = winning_trades / total_trades if total_trades > 0 else 0

        pnl_df = df['pnl_after_fee'].dropna()

        if not pnl_df.empty and pnl_df.std() > 0:
            returns = pnl_df.astype(float)
            sharpe_ratio = returns.mean() / returns.std() * np.sqrt(252)
            cumulative_returns = (1 + returns).cumprod()
            max_drawdown = (cumulative_returns.div(cumulative_returns.cummax()) - 1.0).min()
        else:
            sharpe_ratio = 0.0
            max_drawdown = 0.0

        return {
            'total_trades': total_trades,
            'winning_trades': winning_trades,
            'win_rate': win_rate,
            'total_pnl': total_pnl,
            'sharpe_ratio': sharpe_ratio,
            'max_drawdown': max_drawdown
        }

    def run_walk_forward_backtest(self, symbol) -> Tuple[Dict, pd.DataFrame]:
        if symbol not in self.models:
            print(f"âš ï¸ {symbol}: ãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            return {}, pd.DataFrame()

        df = self.data_processor.get_ohlcv(symbol, timeframe='1h', limit=5000)
        df = self.data_processor.add_features(df)
        df['future_return'] = df['close'].pct_change().shift(-1)
        df['direction'] = (df['future_return'] > 0).astype(int)

        features = [
            'ema_12', 'ema_26', 'ema_50', 'rsi', 'stoch_rsi', 'macd', 'macd_diff', 'adx', 'atr', 'obv',
            'close_lag_1', 'volume_lag_1', 'rsi_lag_1', 'close_lag_2', 'volume_lag_2', 'rsi_lag_2',
            'close_lag_3', 'volume_lag_3', 'rsi_lag_3', 'close_lag_5', 'volume_lag_5', 'rsi_lag_5',
            'bb_hi', 'bb_lo', 'bb_width', 'ema_ratio', 'price_to_ema50', 'vol_change',
            'macd_hist_change', 'rsi_norm', 'macd_norm', 'kc_hi', 'kc_lo', 'super_trend'
        ]

        df_clean = df.dropna()

        if len(df_clean) < MIN_BARS:
            print(f"â„¹ï¸ {symbol}: ãƒ‡ãƒ¼ã‚¿ãŒä¸ååˆ†ã§ã™ã€‚ã‚¦ã‚©ãƒ¼ã‚¯ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ»ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            return {}, pd.DataFrame()

        X = df_clean[features]
        y = df_clean['direction']

        TRAIN_WINDOW_SIZE = 1500
        TEST_WINDOW_SIZE = 500

        all_backtest_results = pd.DataFrame()

        for i in range(TRAIN_WINDOW_SIZE, len(df_clean) - TEST_WINDOW_SIZE, TEST_WINDOW_SIZE):
            train_data = df_clean.iloc[i - TRAIN_WINDOW_SIZE : i].copy()
            test_data = df_clean.iloc[i : i + TEST_WINDOW_SIZE].copy()

            if len(train_data) < TRAIN_WINDOW_SIZE or len(test_data) < TEST_WINDOW_SIZE:
                continue

            model_to_test, _ = self.train_stacking_model(train_data)
            if model_to_test is None: continue

            X_test = test_data[features]
            test_data['stack_pred'] = model_to_test.predict(X_test)
            test_data['stack_prob'] = model_to_test.predict_proba(X_test)[:, 1]

            all_backtest_results = pd.concat([all_backtest_results, test_data])

        return self.run_backtest(all_backtest_results), all_backtest_results


    def score_signal(self, df_row, stack_pred, stack_prob, mtf_agree, candles, last_close):
        score, reasons = 0, []

        prob_score = min(50, max(0, int(50 * stack_prob)))
        score += prob_score
        reasons.append(f"ğŸ§  ãƒ¢ãƒ‡ãƒ«ä¿¡é ¼åº¦ (+{prob_score})")

        if (df_row['ema_12'] > df_row['ema_26'] and stack_pred == 1) or \
           (df_row['ema_12'] < df_row['ema_26'] and stack_pred == 0):
            score += 10; reasons.append("ğŸ“ˆ çŸ­æœŸEMA/é•·æœŸEMAæ–¹å‘ä¸€è‡´ (+10)")

        if df_row['close'] > df_row.get('ema_50', df_row['close']) and stack_pred == 1:
            score += 10; reasons.append("ğŸŸ¢ ä¾¡æ ¼>EMA50 (+10)")

        if (candles['bull_engulf'] and stack_pred == 1) or (candles['bear_engulf'] and stack_pred == 0):
            score += 10; reasons.append("ğŸ§© åŒ…ã¿è¶³ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨æ–¹å‘ä¸€è‡´ (+10)")

        if df_row['adx'] >= 25 and (df_row['ema_12'] > df_row['ema_26'] if stack_pred == 1 else df_row['ema_12'] < df_row['ema_26']):
            score += 10; reasons.append("ğŸ“ ADX>25ã§ãƒˆãƒ¬ãƒ³ãƒ‰æ˜ç¢º (+10)")

        if (df_row['close'] > df_row['kc_hi'] and stack_pred == 1) or \
           (df_row['close'] < df_row['kc_lo'] and stack_pred == 0):
            score += 5; reasons.append("ğŸ“Š ã‚±ãƒ«ãƒˆãƒŠãƒ¼ãƒãƒ£ãƒãƒ«ãƒ»ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆ (+5)")

        if (df_row['close'] > df_row['super_trend'] and stack_pred == 1) or \
           (df_row['close'] < df_row['super_trend'] and stack_pred == 0):
            score += 5; reasons.append("ğŸš€ ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒˆãƒ¬ãƒ³ãƒ‰æ–¹å‘ä¸€è‡´ (+5)")

        if mtf_agree == "agree_long" and stack_pred == 1:
            score += 10; reasons.append("ğŸ§­ 1h/6hä¸Šæ–¹å‘ä¸€è‡´ (+10)")
        elif mtf_agree == "agree_short" and stack_pred == 0:
            score += 10; reasons.append("ğŸ§­ 1h/6hä¸‹æ–¹å‘ä¸€è‡´ (+10)")

        score = int(max(0, min(100, score)))
        return stack_pred, score, reasons

    def calculate_trade_levels(self, last_close: float, atr: float, direction: int, rr_ratio=2.0):
        if atr is None or atr <= 0: return last_close, last_close, last_close, 0.0

        if direction == 1: # ãƒ­ãƒ³ã‚°
            sl_dist = atr * 1.5
            stop_loss = last_close - sl_dist
            target_profit = last_close + sl_dist * rr_ratio
        else: # ã‚·ãƒ§ãƒ¼ãƒˆ
            sl_dist = atr * 1.5
            stop_loss = last_close + sl_dist
            target_profit = last_close - sl_dist * rr_ratio

        risk = abs(last_close - stop_loss)
        reward = abs(target_profit - last_close)
        rr_ratio = reward / risk if risk > 0 else 0.0

        return last_close, stop_loss, target_profit, rr_ratio

    def generate_performance_chart(self, df, symbol):
        df_plot = df.copy()
        df_plot.index = df_plot.index.to_series().dt.floor('H')

        plt.style.use('dark_background')
        fig, ax = plt.subplots(figsize=(12, 6))

        df_plot['correct_combined'] = (df_plot['stack_pred'] == df_plot['direction'])
        df_plot['incorrect_combined'] = (df_plot['stack_pred'] != df_plot['direction'])

        correct_preds = df_plot[df_plot['correct_combined']]
        incorrect_preds = df_plot[df_plot['incorrect_combined']]

        if not correct_preds.empty:
            ax.scatter(correct_preds.index, correct_preds['close'], color='lime', marker='^', s=50, label='Correct Predictions')

        if not incorrect_preds.empty:
            ax.scatter(incorrect_preds.index, incorrect_preds['close'], color='red', marker='x', s=50, label='Incorrect Predictions')

        ax.plot(df_plot.index, df_plot['close'], label='Close Price', color='white', alpha=0.5)

        ax.set_title(f'Prediction Performance for {symbol}')
        ax.set_xlabel('Time')
        ax.set_ylabel('Price (USD)')
        ax.legend()
        plt.tight_layout()

        buf = io.BytesIO()
        plt.savefig(buf, format='png')
        buf.seek(0)
        plt.close(fig)
        return buf.getvalue()

    def generate_feature_importance_chart(self, model, features):
        plt.style.use('dark_background')
        fig, ax = plt.subplots(figsize=(10, 8))

        if hasattr(model, 'feature_importances_'):
            importances = model.feature_importances_
        else: # StackingClassifierã®estimatorsã‹ã‚‰é‡è¦åº¦ã‚’å–å¾—
            try:
                lgbm_importance = model.estimators_[0].feature_importances_
                xgb_importance = model.estimators_[1].feature_importances_
                importances = (lgbm_importance + xgb_importance) / 2
            except Exception:
                importances = np.zeros(len(features))

        feature_importance_df = pd.DataFrame({'feature': features, 'importance': importances})
        feature_importance_df = feature_importance_df.sort_values('importance', ascending=False)

        ax.barh(feature_importance_df['feature'], feature_importance_df['importance'], color='teal')
        ax.set_title('Feature Importance')
        plt.tight_layout()

        buf = io.BytesIO()
        plt.savefig(buf, format='png')
        buf.seek(0)
        plt.close(fig)
        return buf.getvalue()

    def run_analysis_cycle(self):
        print(f"\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ“… åˆ†æé–‹å§‹ {now_utc_str()} â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        candidates = []

        for symbol in self.watchlist:
            try:
                if symbol not in self.models:
                    if not self.load_models(symbol):
                        continue

                stack_model = self.models[symbol]['stack']

                df1h = self.data_processor.get_ohlcv(symbol, timeframe='1h', limit=5000)
                df6h = self.data_processor.get_ohlcv(symbol, timeframe='6h', limit=5000 // 6)

                if df1h is None or df1h.empty or len(df1h) < MIN_BARS or df6h is None or len(df6h) < MIN_BARS // 6:
                    print(f"â­ï¸ {symbol}: ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã‚¹ã‚­ãƒƒãƒ—")
                    continue

                df1h_features = self.data_processor.add_features(df1h)
                df6h_features = self.data_processor.add_features(df6h)

                if df1h_features.empty or df6h_features.empty:
                    print(f"âš ï¸ æŒ‡æ¨™è¨ˆç®—å¾Œã€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ãŒç©ºã«ãªã‚Šã¾ã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
                    print(f"â­ï¸ {symbol}: æŒ‡æ¨™è¨ˆç®—ä¸å¯")
                    continue

                last1h = df1h_features.iloc[-1]
                last6h = df6h_features.iloc[-1]

                long_bias_1h = last1h['ema_12'] > last1h['ema_26'] and last1h['rsi'] >= 55
                long_bias_6h = last6h['ema_12'] > last6h['ema_26'] and last6h['rsi'] >= 55
                mtf_agree = None
                if long_bias_1h and long_bias_6h: mtf_agree = "agree_long"
                elif (not long_bias_1h) and (not long_bias_6h): mtf_agree = "agree_short"

                candles = detect_candles(df1h[['open','high','low','close']].tail(3))

                features_to_predict = [
                    'ema_12', 'ema_26', 'ema_50', 'rsi', 'stoch_rsi', 'macd', 'macd_diff', 'adx', 'atr', 'obv',
                    'close_lag_1', 'volume_lag_1', 'rsi_lag_1', 'close_lag_2', 'volume_lag_2', 'rsi_lag_2',
                    'close_lag_3', 'volume_lag_3', 'rsi_lag_3', 'close_lag_5', 'volume_lag_5', 'rsi_lag_5',
                    'bb_hi', 'bb_lo', 'bb_width', 'ema_ratio', 'price_to_ema50', 'vol_change',
                    'macd_hist_change', 'rsi_norm', 'macd_norm', 'kc_hi', 'kc_lo', 'super_trend'
                ]
                latest_features_df = df1h_features[features_to_predict].iloc[[-1]]

                stack_pred = int(stack_model.predict(latest_features_df)[0])
                stack_prob = float(stack_model.predict_proba(latest_features_df)[0][stack_pred])

                combined_pred, quality, reasons = self.score_signal(last1h, stack_pred, stack_prob, mtf_agree, candles, float(last1h['close']))
                entry, sl, tp, rr = self.calculate_trade_levels(float(last1h['close']), float(last1h['atr']), combined_pred)

                candidates.append({
                    "symbol": symbol, "quality": quality, "entry": entry, "sl": sl, "tp": tp,
                    "combined_pred": combined_pred, "stack_prob": stack_prob,
                    "reasons": reasons, "mtf": mtf_agree,
                    "candles": candles, "rr": rr, "atr": float(last1h.get('atr', 0.0)),
                    "backtest": {},
                    "backtest_df": self.backtest_data.get(symbol, pd.DataFrame())
                })
                print(f"âœ… {symbol}: ã‚¹ã‚³ã‚¢{quality}")
                gc.collect()

            except Exception as inner_e:
                print(f"âš ï¸ {symbol} ã§è­¦å‘Š: {inner_e}")
                traceback.print_exc(file=sys.stdout)
                continue

        if not candidates:
            print("ğŸ™… åˆ†æå¯¾è±¡ãªã—ã€‚")
        else:
            notifiable_candidates = sorted([c for c in candidates if c['quality'] >= QUALITY_NOTIFY_THRESHOLD], key=lambda x: x['quality'], reverse=True)
            if not notifiable_candidates:
                max_score = max(c['quality'] for c in candidates) if candidates else 0
                print(f"â„¹ï¸ é€šçŸ¥ãªã—ï¼ˆæœ€é«˜ã‚¹ã‚³ã‚¢ {max_score} / é–¾å€¤ {QUALITY_NOTIFY_THRESHOLD}ï¼‰")
            else:
                print(f"ğŸ‰ ä»¥ä¸‹ã®ã‚·ãƒ³ãƒœãƒ«ãŒé€šçŸ¥é–¾å€¤ã‚’æº€ãŸã—ã¾ã—ãŸï¼ˆ{len(notifiable_candidates)}ä»¶ï¼‰")
                for candidate in notifiable_candidates:
                    print(f"ğŸƒ {candidate['symbol']} ã§ã‚¦ã‚©ãƒ¼ã‚¯ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œä¸­...")
                    backtest_results, backtest_df = self.run_walk_forward_backtest(candidate['symbol'])
                    candidate['backtest'] = backtest_results
                    candidate['backtest_df'] = backtest_df

                    self.notify_signal(candidate)

    def notify_signal(self, candidate):
        icon = symbol_icon(candidate['symbol'])
        stars = "ğŸŸ¡" * int(candidate['quality']//20) + "âšª" * (5 - int(candidate['quality']//20))
        dir_text = "ğŸ“ˆ <b>ãƒ­ãƒ³ã‚°å„ªå‹¢</b>" if candidate['combined_pred'] == 1 else "ğŸ“‰ <b>ã‚·ãƒ§ãƒ¼ãƒˆå„ªå‹¢</b>"

        patt_emo = []
        if candidate['candles']['bull_pin']: patt_emo.append("ğŸªå¼·æ°—ãƒ”ãƒ³ãƒãƒ¼")
        if candidate['candles']['bear_pin']: patt_emo.append("ğŸªå¼±æ°—ãƒ”ãƒ³ãƒãƒ¼")
        if candidate['candles']['bull_engulf']: patt_emo.append("ğŸ§©é™½ã®åŒ…ã¿è¶³")
        if candidate['candles']['bear_engulf']: patt_emo.append("ğŸ§©é™°ã®åŒ…ã¿è¶³")
        patt_str = " / ".join(patt_emo) if patt_emo else "ï¼ˆé¡•è‘—ãªã—ï¼‰"

        backtest_info = candidate.get('backtest', {})
        total_pnl_str = f"<code>{backtest_info.get('total_pnl', 0.0):.2%}</code>" if 'total_pnl' in backtest_info else "N/A"
        pnl_sign = "ğŸŸ¢" if backtest_info.get('total_pnl', 0.0) >= 0 else "ğŸ”´"

        msg = (
f"{icon} <b>{candidate['symbol']}</b> ã‚·ã‚°ãƒŠãƒ«ç™ºç”Ÿ ğŸ¯\n"
f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
f"{dir_text}\n"
f"è©•ä¾¡: {stars} <b>{candidate['quality']}/100</b>\n"
f"ãƒ¢ãƒ‡ãƒ«ä¿¡é ¼åº¦: <code>{candidate['stack_prob']:.2f}</code>\n"
f"ATR: <code>{fmt_price(candidate['atr'], 4)}</code>\n"
f"ãƒ‘ã‚¿ãƒ¼ãƒ³: {patt_str}\n"
f"\n"
f"ğŸ“Œ ã‚¨ãƒ³ãƒˆãƒªãƒ¼: <code>{fmt_price(candidate['entry'])}</code>\n"
f"ğŸ›‘ æåˆ‡ã‚Š(SL): <code>{fmt_price(candidate['sl'])}</code>\n"
f"ğŸ¯ åˆ©ç¢º(TP): <code>{fmt_price(candidate['tp'])}</code>\n"
f"ğŸ“ ãƒªã‚¹ã‚¯ãƒªãƒ¯ãƒ¼ãƒ‰: <code>{candidate['rr']:.2f}</code>\n"
f"\n"
f"ğŸ“Š <b>ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚µãƒãƒªãƒ¼ (ã‚¦ã‚©ãƒ¼ã‚¯ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰)</b>\n"
f" - ç·å–å¼•æ•°: {backtest_info.get('total_trades', 'N/A')}\n"
f" - å‹ç‡: <code>{backtest_info.get('win_rate', 0.0):.0%}</code>\n"
f" - ç·æç›Š: {pnl_sign} {total_pnl_str}\n"
f" - ã‚·ãƒ£ãƒ¼ãƒ—ãƒ»ãƒ¬ã‚·ã‚ª: <code>{backtest_info.get('sharpe_ratio', 0.0):.2f}</code>\n"
f" - æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³: <code>{backtest_info.get('max_drawdown', 0.0):.2%}</code>\n"
f"\n"
f"æ ¹æ‹ :\n- " + "\n- ".join([escape_html(r) for r in candidate['reasons']]) + "\n"
f"â° {now_utc_str()}"
        )

        try:
            print(f"ğŸ“¨ Telegramé€ä¿¡ã‚’è©¦è¡Œ: {candidate['symbol']} / ã‚¹ã‚³ã‚¢{candidate['quality']}")

            if not candidate['backtest_df'].empty:
                chart_data = self.generate_performance_chart(candidate['backtest_df'], candidate['symbol'])
                self.notifier.send_photo(chart_data, msg)
            else:
                self.notifier.send_message(msg)

            # ç‰¹å¾´é‡é‡è¦åº¦ãƒãƒ£ãƒ¼ãƒˆã‚’ç”Ÿæˆ
            if candidate['symbol'] in self.models and 'stack' in self.models[candidate['symbol']]:
                features = [
                    'ema_12', 'ema_26', 'ema_50', 'rsi', 'stoch_rsi', 'macd', 'macd_diff', 'adx', 'atr', 'obv',
                    'close_lag_1', 'volume_lag_1', 'rsi_lag_1', 'close_lag_2', 'volume_lag_2', 'rsi_lag_2',
                    'close_lag_3', 'volume_lag_3', 'rsi_lag_3', 'close_lag_5', 'volume_lag_5', 'rsi_lag_5',
                    'bb_hi', 'bb_lo', 'bb_width', 'ema_ratio', 'price_to_ema50', 'vol_change',
                    'macd_hist_change', 'rsi_norm', 'macd_norm', 'kc_hi', 'kc_lo', 'super_trend'
                ]
                importance_chart = self.generate_feature_importance_chart(self.models[candidate['symbol']]['stack'], features)
                self.notifier.send_photo(importance_chart, f"<b>{candidate['symbol']}</b> ç‰¹å¾´é‡é‡è¦åº¦ãƒãƒ£ãƒ¼ãƒˆ")

            print(f"âœ… Telegramé€ä¿¡æˆåŠŸ: {candidate['symbol']}")
        except Exception as e:
            print(f"âŒ Telegramé€ä¿¡å¤±æ•—: {candidate['symbol']} / åŸå› : {e}")

# ================== ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ã®å®Ÿè¡Œ ==================
if __name__ == "__main__":
    notifier = TelegramNotifier(TELEGRAM_TOKEN, TELEGRAM_CHAT_ID)
    data_processor = DataProcessor(exchange)

    # åˆå›å®Ÿè¡Œæ™‚ã€ãƒ¢ãƒ‡ãƒ«ã¨ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯ã¨è¨“ç·´
    bot = TradingBot(data_processor, notifier, WATCHLIST)

    print("ğŸš€ è¶…é«˜æ€§èƒ½ãƒœãƒƒãƒˆèµ·å‹•:", now_utc_str())
    print(f"ğŸ”” é€šçŸ¥ã‚¹ã‚³ã‚¢ã®é–¾å€¤: {QUALITY_NOTIFY_THRESHOLD}")

    last_alive_notification = time.time()
    last_ping_time = time.time()

    if notifier.is_enabled:
        test_message = (
            f"<b>âœ… è¶…é«˜æ€§èƒ½ãƒœãƒƒãƒˆ èµ·å‹•æˆåŠŸ</b> âœ…\n\n"
            f"ã“ã‚Œã¯èµ·å‹•æ™‚ã«é€ä¿¡ã•ã‚Œã‚‹ãƒ†ã‚¹ãƒˆé€šçŸ¥ã§ã™ã€‚\n"
            f"é€šçŸ¥è¨­å®šã¯æ­£å¸¸ã«å®Œäº†ã—ã¦ã„ã¾ã™ã€‚\n\n"
            f"æœ€åˆã®åˆ†æã‚µã‚¤ã‚¯ãƒ«ã¯ã¾ã‚‚ãªãé–‹å§‹ã•ã‚Œã¾ã™ã€‚\n"
            f"â° {now_utc_str()}"
        )
        notifier.send_message(test_message)
        print("ğŸ‘ ãƒ†ã‚¹ãƒˆé€šçŸ¥ã‚’é€ä¿¡ã—ã¾ã—ãŸã€‚")

    while True:
        try:
            bot.run_analysis_cycle()

            elapsed_since_last_ping = time.time() - last_ping_time
            if elapsed_since_last_ping >= PING_INTERVAL_SEC:
                try:
                    requests.get("https://google.com")
                    print(f"ğŸŒ æ¥ç¶šç¶­æŒç”¨pingã‚’é€ä¿¡ã—ã¾ã—ãŸã€‚ æ¬¡å›pingã¾ã§ {PING_INTERVAL_SEC//60}åˆ†")
                except Exception as e:
                    print(f"âŒ æ¥ç¶šç¶­æŒpingã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                finally:
                    last_ping_time = time.time()

            elapsed_since_last_notify = time.time() - last_alive_notification
            if elapsed_since_last_notify >= ALIVE_NOTIFY_INTERVAL_SEC:
                alive_message = f"<b>ğŸ’– Botã¯ç¨¼åƒä¸­ã§ã™ï¼</b>\n\næœ€çµ‚åˆ†ææ™‚åˆ»: {now_utc_str()}"
                notifier.send_message(alive_message)
                last_alive_notification = time.time()
                print("ğŸ’– ç¨¼åƒä¸­é€šçŸ¥ã‚’é€ä¿¡ã—ã¾ã—ãŸã€‚")

        except Exception as e:
            print("ğŸ’¥ ä¾‹å¤–ç™ºç”Ÿï¼ˆç¶™ç¶šï¼‰:", e)
            traceback.print_exc(file=sys.stdout)

        print(f"ğŸ•’ {MAIN_LOOP_SLEEP_SEC//60:.0f}åˆ†å¾…æ©Ÿ â†’ {now_utc_str()}")
        time.sleep(MAIN_LOOP_SLEEP_SEC)
